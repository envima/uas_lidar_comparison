---
title: "UAS Pointclouds vs. Lidar Pointclouds for structual analysis of forests"
author: "Marvin Ludwig, Simon Seyfried, Nico Friess, Chris Reudenbach, Thomas Nauss"
output:
  html_document:
    df_print: paged
  pdf_document: default
bibliography: /home/marvin/literature/zotero/references.bib
editor_options:
  chunk_output_type: console
---

```{r setup, include = FALSE}
library(tidyverse)
library(viridis)
library(knitr)
library(extrafont)
root_folder = "/home/marvin/casestudies/uas_lidar_comparison/"


knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)
#knitr::opts_knit$set(root.dir = root_folder)


```

# Introduction


## Use of LiDAR in nature conservation and forestry

Light detection and ranging (LiDAR) remote sensing is a well established tool in the assessment of biodiversity and nature conservation. From the raw 3D pointclouds, a large variety of information can be derived helping to explain and manage critical environmental processes like shrub encroachment in grasslands [@Madsen2020], forest health assessment [@Duncanson2018] or the monitoring of wetland loss [@Montgomery2019]. One of the most common applications of LiDAR data is the description of the structure of landscapes, which then serve as drivers for species occurrence [@Carrasco2019; @Melin2016; @Froidevaux2016] or as indicators for biodiversity [@Hilmers2018; @Simonson2014].

Especially forest environments are a very popular target for analysis with LiDAR data [@Beland2019]. Structural information can be derived at the level of individual tree groups [@Jeronimo2018] or individual crowns in sparse forest stands [@Silva2016]. However a more operational and well established approach is, to transfer the structural information of the 3D pointcloud into a regular 2D grid, commonly referred to as LiDAR indices. The vegetation structure then is represented e.g. as the vertical distribution or the maximum height of points in one grid cell [@Bakx2019]. In order to preserve some of the original 3D information, there are indices which work on voxel (i.e. horizontal slices of the pointcloud) and can represent different strata of the forest canopy [e.g. @Alexander2014]. The reliability of LiDAR indices is usually shown by referring them to field measurements of established forest structural indices like canopy cover and canopy height [@Lee2018; @Alexander2014], stand density [@Lee2018a] or leaf area [@Kamoske2019]. 


## Problems with LiDAR

Despite their relevance in conservation and research, LiDAR data has some major drawbacks, mainly in their cost and accessibility. Professional LiDAR sensors and airborne data acquisition are expensive and often distributed commercially. Data provided by governmental institutions is still often not publicly distributed. Further, the temporal resolution of the data is low making them not suitable for monitoring or applications which require different seasonal conditions. Researchers also have no control over the acquisition time, however the environmental condition (e.g. leaf-on or leaf-off) has a direct impact on the derived LiDAR indices and therefore the product quality [@Davison2020]. It can further be beneficial to combine leaf off and leaf on LiDAR data, e.g. for improving the model quality of tree species classifications [@Shi2018].

## Unmannes Aerial Systems and Digital Aerial Photogrammetry

Lately, Unmanned Aerial Systems (UAS) underwent a rise in popularity for environmental research. Especially consumer grade drones can help to overcome some shortcomings of airborne surveys. Quick and flexible imagery access in moderately large areas make UAS promising for the monitoring of agricultural or natural systems [@Manfreda2018; @Fallati2020]. Depending on flight conditions, data acquisition could be on a near daily basis. This opens up the possibility of surveying multi-temporal landscape features like plant phenology which improves classifications of vegetation types [@VanIersel2018].  
In conjunction with LiDAR sensors, UAS have found use in all major environmental science domains e.g. landslide monitoring [@Pellicani2019], savanna bush encroachment [@Madsen2020], forest inventory [@Wallace2012; @Wallace2014] or land vegetation monitoring [@Sankey2018]. Unfortunately, the cost of a LiDAR UAS currently exceeds the low budged approach many researchers are looking for.  
With recent improvements in photogrammetric aerial image processing, an alternative to LiDAR pointclouds is available. In overlapping images with a camera (RGB, multi- or hyperspectral), the structural information can be derived by detecting distinct features in the individual images and projecting them into the 3D space [@Iglhaut2019]. Software packages like Agisoft Metashape or OpenDroneMap, make operational photogrammetic workflows possible [@Ludwig2020] which increases the availability of Digital Aerial Photogrammetry (DAP) pointclouds for a wide variety of applications. Especially the estimation of canopy heights in forest [@Fawcett2019; @Krause2019; @Michez2020; @Ganz2019] and agriculture [@Gruner2019] compare very well to field measurements and estimations from LiDAR or Terrestrial Laser Scanning [@Malambo2018]. The straightforward data access of DAP is beneficial for the monitoring of tree growth rates [@Guerra-Hernandez2017] and crops [@Moeckel2018]. Previous comparisons also revealed the potential of DAP pointclouds as a substitude for LiDAR when estimating common forest attributes [e.g. @Ullah2019; @Cao2019] and to a lesser extent biomass estimations in the tropics [@Ota2015]. A systematic comparison between both data types is still missing.  

## Multi-temporal pointclouds

One major drawback of DAP pointclouds is, that they only contain surface points which are visible in the individual images. In forest environments, it is very unlikely that points below the canopy are surveyed. The selling feature of LiDAR pointclouds on the other hand is the ability of the laser scanner to reaches below the canopy. This information can be used to e.g. to differentiate between ground and non-ground point or assess different strata of the forest. With the combination of DAP pointclouds from different phenological stages (leaf-off and leaf-on) this drawback could be negated.  
Therefore, this study demonstrates the potential of multitemporal pointclouds derived from digital aerial photogrammetry for forest structural analysis. Commonly applied forest structural indicators will be compared between DAP and LiDAR pointclouds for different spatial scales and different phenological stages of a deciduous forest. In addition we propose the combination of multiple DAP pointclouds as a way to improve their information value and better comparability to LiDAR data. We analyze the DAP pointclouds with regards to the following hypothesis:

**Hypothesis 1:** When compared to LiDAR pointclouds, the quality of structural indices from DAP pointclouds depend on the phenological stages of a deciduous forest.

**Hypothesis 2:** Multi-temporal DAP pointclouds are superior than mono-temporal pointclouds and are suitable to complement LiDAR derived pointclouds for forest structural analysis.



# Methods

## Study Area


As the study area serves a 200 x 200 m part of a mixed deciduous forest near Marburg (Germany). The area consists of oaks (\textit{Quercus spec.}) and beeches (\textit{Fagus sylvatica}) and represent a typical stand in a managed deciduous forest. Terrain elevation ranges from 250 m to 275 m a.s.l. Stem positions of 500 trees were acquired by using a differential GPS (Zenith 35 Pro, GeoMax Widnau Switzerland) with a positioning accuracy of 0.05 m.\\


## Datasets

The LiDAR data was acquired with a Riegl LMS-Q780 sensor in early spring 2018 under leaf off conditions (Tab. \@ref(tab:tabDatasetOverview)) and provided by the Hessian Agency for Nature Conservation, Environment and Geology - HLNUG. The original pointcloud had an average point density of XX points per square meter with a georeferencing accuracy of 0.3 m horizontally and 0.15 m vertically (Novatel OEM4 GNSS). The LiDAR pointcloud was already classified into ground points and non-ground points by the data provider.  
The DAP pointclouds were acquired with a 3DR Solo Quadrocopter (3D Robotics, Inc., Berkeley CA, USA) and a GoPro Hero 7 camera (GoPro Inc., San Mateo CA, USA) between August and December of 2020. The flight tasks were planned in a uniform altitude above ground at 110 m resulting in a ground sampling distance of 5.6 cm, a side overlap of 75% and a front overlap of 90%. Using the photogrammetric software Metashape (Agisoft LLC, St. Petersburg, Russia), sparse pointclouds were computed from the individual images of each flight. Each sparseclouds was georeferenced with 10 ground control points surveyed with the Real Time Kinematic (RTK) GNSS (Global Navigation Satellite System) device Geomax Zenith 35 (GeoMax AG, Widnau, Switzerland). A detailed explanation of the applied photogrammetic workflow is describe in [@Ludwig2020]. After the referencing, dense pointclouds were computed for each flight from non-resampled depth maps and moderate filtering. 




```{r tabDatasetoverview}

df = read.csv("tables/dataset_overview.csv", header = FALSE)
dfheader = df[1,]
df = df[-1,]

kable(x = df, col.names = dfheader ,row.names = FALSE)

```


## Pointcloud preprocessing and combination

Forest structural analysis from pointclouds requires a canopy height model (CHM) i.e. the point height normalized by the terrain height from a digital elevation model (DEM). Since it is difficult (sometimes impossible) to identify ground points in vegetated areas in DAP pointclouds they are mostly not suitable for this task [@Ota2015]. Other sources of DEMs are therefore utilized e.g. by interpolation of surveyed ground points [@Gruner2019]. Since terrain elevation does usually not change rapidly over time available LiDAR data is also viable most of the time [@Ullah2019].  
In order to increase the comparability between the pointclouds, each one was homogenized to a density of 50 points per square meter. The classified LiDAR ground points were used to compute a DEM with a spatial resolution of 1 m using a k-nearest neighbor algorithm with inverse distance weighting. The DEM was used to normalize the height of each pointcloud which effectively results in a canopy height model (CHM). To eliminate the effects of ground points in the upcoming index calculation, points below 2 m canopy height were removed.  
DAP pointclouds from five different phenological stages during fall 2020 were combined with the leaf-off DAP pointcloud from 2020-12-11. These five multitemporal pointclouds were preprocessed the same way as the individual pointclouds (Fig. \@ref(fig:figWorkflow)). All pointcloud based methods and computations were done in R using the lidR package [@Roussel2020].


```{r figWorkflow}
knitr::include_graphics(path = "figures/pointcloud_processing.pdf")
```



## Calculation of LiDAR indices

Previous studies showed, that there are strong correlations between the most commonly used LiDAR indices [@Shi2018]. we picked 4 commonly used indices from [@Bakx2019]

In the review by @Bakx2019, over 10 different studies used this 



### Canopy height

The most common application of pointclouds is the estimation of the canopy height. The simplest method is the maximum absolute height of the points in each raster cell $Z_{max}$. However a more realistic approach which is less prone to extreme values is the average height of all points in the 95 percentile ($Z_{mean95}$, Eq. 1). Both indices are included in more than 10 studies listed in @Bakx2019.

$$ Z_{mean95} = \frac{\Sigma(Z_{95})}{N_{95}} \;\;\; [1]$$

### Canopy surface models

To assess the overall vertical structure of the canopy, it is a common practice to regard only the first returns of the LiDAR pointclouds and treat them as the so called canopy surface model (CSM). DAP pointclouds do not have return values, however it is a reasonable assumption that here every point represent the canopy, since only spots visible from above the canopy are possible. Therefore the indices $Z\_mean\_csm$ and $Z\_sd\_csm$ were applied to only the first returns of the LiDAR data but all points of the DAP pointclouds.


### Canopy heterogeneity

To assess the horizontal heterogeneity of the canopy, we used the aforementioned indices with a 2m resolution and calculated their standard deviation in a 5 x 5 m grid, resulting in a grid with 10m resolution. The vertical canopy structure was assessed by calculating 10 percentiles of the point height in each raster cell. Further, the pointcloud was divided into voxels of 2m height. For each pixel we calculated the number of points in each voxel height.

### Normalizing indices values

For better comparability between the different indices, the actual values got normalized to values between zero and one by subtracting the minimum value and divide by the range of the index (Equation 3).

$$ Ind_{norm} = \frac{Ind - min(Ind)}{max(Ind) - min(Ind)} \;\;\;[3]$$





# Results

## Direct comparison of Lidar and DAP

```{r figVertpointsmono, fig.cap="Comparison of the vertical point distribution of LiDAR and single date DAP"}

p = readRDS(file.path(root_folder, "data/level0/pointcloud_height_comparison_single.RDS"))
p
```



## Comparison of Indices at different resolutions

```{r figBakx1resolution}
bakx_plots = readRDS(file.path(root_folder, "data/results/scatterplots/lidar_densecloud_bakx1_resolutions_plots.RDS"))
bakx_plots[[1]]
```


## Comparison of acquisiton dates

```{r figBakx1dates, fig.cap="Comparison of DAP acquisition dates. The indices were calculated in a 4m resolution"}
bakx_plots = readRDS(file.path(root_folder, "data/results/scatterplots/lidar_densecloud_bakx1_4m_dates.RDS"))
bakx_plots
```


## Horizontal heterogenity for different dates


```{r figHorizontalsd, fig.cap= "Standard deviation of the indices in a 2m resolution aggeragted to a 10m resolution"}
het1 = readRDS(file.path(root_folder, "data/results/scatterplots/lidar_densecloud_bakx1sd_dates_plots.RDS"))
het1

```


```{r figHorizontalsdMulti}
het2 = readRDS(file.path(root_folder, "data/results/scatterplots/lidar_multi_bakx1sd_dates_plots.RDS"))
het2
```


## Vertical structure

```{r figZvoxel1}
voxel_plots = readRDS(file.path(root_folder, "data/results/scatterplots/lidar_densecloud_zvoxel_resolutions_plots.RDS"))
voxel_plots[[1]]
```

## Using Multitemporal pointclouds

all these plots use a 2m resolution for the indice calculation

```{r figSummaryIndices, fig.cap="R2 values of linear models between indices of LiDAR pointclouds and DAP pointclouds."}
cors = readRDS(file.path(root_folder, "data/results/lidar_densecloud_correlations/lidar_denseclouds_lm.RDS")) %>% 
  filter(datasource != "lidar") %>% 
  filter(metric_group == "bakx1") %>% 
  filter(metric != "z_shannon") %>% 
  filter(resolution == 4)


ggplot(cors, aes(x = paste0(date, "_",datasource), y = metric, fill = Rsq))+
  geom_raster(alpha = 0.8)+
  scale_fill_gradientn(colors = viridis(50))+
  geom_text(mapping = aes(label = Rsq), col = "black")+
  scale_x_discrete(name = NULL, expand = c(0,0))+
  scale_y_discrete(name = NULL, expand = c(0,0))+
  theme(panel.background = element_blank())+
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

```


```{r figSummaryHeterogenity, fig.cap = "R2 values of linear models between the 10 m standard deviation of indices of LiDAR pointclouds and DAP pointclouds."}

cors = readRDS(file.path(root_folder, "data/results/lidar_densecloud_correlations/lidar_denseclouds_lm.RDS")) %>% 
  filter(datasource != "lidar") %>% 
  filter(metric_group == "bakx1_sd") %>% 
  filter(resolution == 2)


ggplot(cors, aes(x = paste0(date, "_",datasource), y = metric, fill = Rsq))+
  geom_raster(alpha = 0.8)+
  scale_fill_gradientn(colors = viridis(50))+
  geom_text(mapping = aes(label = Rsq), col = "black")+
  ggtitle(cors$metric_group)+
  theme_bw()+
  theme(axis.text.x = element_text(angle = 45, vjust = 0.5))

```


```{r figSummaryVoxelheight}

cors = readRDS(file.path(root_folder, "data/results/lidar_densecloud_correlations/lidar_denseclouds_lm.RDS")) %>% 
  filter(datasource != "lidar") %>% 
  filter(metric_group == "zVoxel") %>% 
  filter(resolution == 2)


ggplot(cors, aes(x = paste0(date, "_",datasource), y = metric, fill = Rsq))+
  geom_raster(alpha = 0.8)+
  scale_fill_gradientn(colors = viridis(50))+
  geom_text(mapping = aes(label = Rsq), col = "black")+
  scale_x_discrete(name = NULL, expand = c(0,0))+
  scale_y_discrete(name = NULL, expand = c(0,0))+
  theme(panel.background = element_blank())+
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

```

```{r figSummaryVoxelpoints}

cors = readRDS(file.path(root_folder, "data/results/lidar_densecloud_correlations/lidar_denseclouds_lm.RDS")) %>% 
  filter(datasource != "lidar") %>% 
  filter(metric_group == "nVoxel") %>% 
  filter(metric != "n_points") %>% filter(metric != "n_points38") %>% 
  filter(resolution == 2)


ggplot(cors, aes(x = paste0(date, "_",datasource), y = metric, fill = Rsq))+
  geom_raster(alpha = 0.8)+
  scale_fill_gradientn(colors = viridis(50))+
  geom_text(mapping = aes(label = Rsq), col = "black")+
  scale_x_discrete(name = NULL, expand = c(0,0))+
  scale_y_discrete(name = NULL, expand = c(0,0))+
  theme(panel.background = element_blank())+
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

```


# Discussion

Outlook: posibility of individual tree segmentation and then relate to stand variable (Sackov 2019)
or even tree health (Belmonte 2018)


Bad correlations in lower voxel between LiDAR and UAS pointcloud might be because leaf off UAS is able to capture more branches and stems, therefore more points in lower part of the pointcloud (see Fig Distributions). UAS therefore might be better than LiDAR to capture understory vegetation (or at least the potential for understory vegetation) than leaf off LiDAR data
The influence of understory to forest classifications is one common challenge in many studies and identified as a crucial week point

Real strength lies in the combination of multiple data types, e.g. combining UAS photogrammetriy and LiDAR to monitor river channels [@Flener2013]

mix of pointclouds and images to classify individual trees [@Xu2020]


EBV framework with 3D information: height, cover and structural complexity
Heterogenous data sources: requires the comparability of Lidar and photogrammetrically recieved pointclouds [@Valbuena2020]

The quality and viability of UAS pointclouds have to be assessed in terms of comparability to Lidar pointclouds (since Lidar structural analysis is the standard in many studies)

# Text fragments, Backlog


The main challange for further usage of Lidar data in a forest environment is the detection of individual trees. This enables the estimation of tree related parameters such as diameter at breast height, timber volume or crown related metrics [@VanLeeuwen2010]. Forest structure then can be described as the sum of the structure of individual trees [e.g. their height and biomass @Ferraz2016] and the species composition (REF). This could give new insights into ecosystem functioning, since many processes and species distributions depend on functions provided by trees or their related microhabitats (REF). Further, monitoring of individual tree health and drought could be applied in forestry.



### Canopy cover

Usually canopy cover is derived from LiDAR as follows (over 10 different studies cited in @Bakx2019 Supplementary Material 3)

$$ \frac{N_{p > x}}{N_{t}} * 100 $$

with percentage of returns (Np > x) above x meter above ground level at the raster resolution. Nt is the total number of returns. @Bakx2019 also mentiones Farrell et al. 2013 in which a tow part procedure is described: First cover is estimated from aerial photographs, then it is corrected by excluding areas with low canopy height derived from LiDAR. UAS based pointclouds might very suitable for this approach, since the pointcloud and the aerial image are received in the same workflow.

# References

