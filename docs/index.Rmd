---
title: "UAS Pointclouds vs. Lidar Pointclouds for structual analysis of forests"
output: html_document
author: "Marvin Ludwig, Simon Seyfried, Chris Reudenbach, Thomas Nauss"
bibliography: /home/marvin/literature/zotero/references.bib
editor_options: 
  chunk_output_type: console
---

```{r setup, include = FALSE}
library(tidyverse)
library(viridis)
library(knitr)
root_folder = "/home/marvin/casestudies/uas_lidar_comparison/"


knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)
#knitr::opts_knit$set(root.dir = root_folder)


```

# Introduction


## Use of LiDAR in nature conservation and forestry

Light detection and ranging (LiDAR) remote sensing is a well established tool in the assessment of biodiversity and nature conservation. 
From the raw 3D pointclouds, a large variety of information can be derived helping to explain and manage critical environmental processes like shrub encroachment in grasslands [@Madsen2020], forest health assessment [@Duncanson2018] or the monitoring of wetland loss [@Montgomery2019]. One of the most common applications of LiDAR data is the description of the structure of landscapes, which then serve as drivers for species occurrence [@Carrasco2019; @Melin2016; @Froidevaux2016] or as indicators for biodiversity [@Hilmers2018; @Simonson2014].

Especially forest environments are a very popular target for analysis with LiDAR data [@Beland2019]. Structural information can be derived at the level of individual tree groups [@Jeronimo2018] or individual crowns in sparse forest stands [@Silva2016]. However a more operational and well established approach is, to transfer the structural information of the 3D pointcloud into a regular 2D grid, commonly referred to as LiDAR indices. The vegetation structure then is represented e.g. as the vertical distribution or the maximum height of points in one grid cell [@Bakx2019]. In order to preserve some of the original 3D information, there are indices which work on voxel (i.e. horizontal slices of the pointcloud) and can represent different strata of the forest canopy [e.g. @Alexander2014]. The reliability of LiDAR indices is usually shown by referring them to field measurements of established forest structural indices like canopy cover and canopy height [@Lee2018; @Alexander2014], stand density [@Lee2018a] or leaf area [@Kamoske2019]. 




## Problems with LiDAR

Despite their relevance in conservation and research, LiDAR data has some major drawbacks, mainly in their cost and accessibility. Professional LiDAR sensors are expensive and  data acquisition are expensive and often distributed commercially. Data provided by governmental institutions are still irregularly available and often not publicly distributed. Further, the temporal resolution of the data is low (by law every 3 years in Germany) making them not suitable for monitoring or applications which require different seasonal conditions. Researchers also have no control over the acquisition time, however the environmental condition (e.g. leaf-on or leaf-off) has a direct impact on the derived LiDAR indices and therefore the product quality [@Davison2020]. It can also be beneficial to combine leaf off and leaf on LiDAR data, e.g. for improving the model quality of tree species classifications [@Shi2018].

- some words and publications about LiDAR UAS


## Use of UAS digital aerial photogrammetry

With the recent development of Unmanned Aerial Systems (UAS) and improvements of photogrammetric image processing, an alternative to LiDAR pointclouds is available. Quick data access in moderately large areas makes UAS data promising for the monitoring of agricultural or natural systems [@Manfreda2018]. Depending on flight conditions, these pointclouds could be acquired on a near daily basis. Especially in forest environments, research can benefit from vegetation structural information retrieved from UAS data. 

mix of pointclouds and images to classify individual trees [@Xu2020]
Tree height works good in UAS [@Fawcett2019]

However, if trees are detected, the height measurement is well established and consistent across multiple flight dates [e.g. @Krause2019] 


Monitoring of Canopy height of crops with multitemporal UAS based CHMs, DEM was build manually with known ground point interpolation [@Gruner2019]


also comparing well to TLS based pointclouds when evaluating plant height in agriculture [@Malambo2018]


## Previous comparisons of UAS and Lidar

comparison of lidar and uav CHM [@Michez2020]


Comparison of Lidar and UAS based pointclouds for individual tree height [@Ganz2019] revealed very good compariability. Quality of UAS based studies is highly depended on the accuracy of data acuisition and ulitmately proper georeferencing. Dealed with that in Ludwig 2020! 


Comparisons revealed good potential of UAS pointclouds as a substitude for lidar when estimating common forest attributes [e.g. @Ullah2019; @Cao2019] and to a lesser extent biomass estimations in the tropics [@Ota2015]

DEM clearly is the week point of photogrammetry [@Ota2015]
When comparing ALS and UAS, using a ALS derived DTM is common in order to normalize the Pointclouds [e.g. @Ullah2019]


UAS pointclouds do not have return values which many Lidar indices depend on. Every point is a first return so we cannot get below a developed canopy. These return values however are crucial for LiDAR point classification (e.g. differentiate between ground and non ground point).


EBV framework with 3D information: height, cover and structural complexity
Heterogenous data sources: requires the comparability of Lidar and photogrammetrically recieved pointclouds [@Valbuena2020]

The quality and viability of UAS pointclouds have to be assessed in terms of comparability to Lidar pointclouds (since Lidar structural analysis is the standard in many studies)


## Previous work of multitemporal UAS

Multitemporal UAV for monitoring coral reefs [@Fallati2020]

Multitemporal UAS can benefit monitoring, e.g. tree growth rates [@Guerra-Hernandez2017] or crops [@Moeckel2018]

Multitemporal UAS orthoimages can enhance classification of vegetation types slightly [@VanIersel2018], makes use of plant phenology, most imprtant were july and september because there, green vegetation were at the maximum

Biomass of single trees (in a park) much better under leaf off conditions [@Ye2019]




If the positional accuracy of the individual photogrammetric pointclouds is high enough (previously shown in @Ludwig2020, it is a resonable assumption to combine pointclouds from different phenological stages in order to get a full 3D model of the forest. 

Since photogrammetically received pointclouds only capture the surface and do not penetrate the forest canopy like Lidar pointclouds, different phenological stages should capture different vertical layers of the forest canopy.


## What we do

Since most LiDAR indices are are strongly correlated [@Shi2018] we picked 4 commonly used indices from [@Bakx2019]


This study demonstates the usability of multitemporal pointclouds derived from digital aerial photogrammetry for forest structural analysis. Commonly applied forest structural indicators will be compared between DAP and LiDAR pointclouds for different spatial scales and different phenological stages of a deciduous forest. In addition we propose the combination of multiple DAP pointclouds as a way to improve their information value and better comparability to LiDAR data. All derived pointcloud indicators will also be related to commonly used forest structural indicators from field surveys of trees.

**Hypothesis 1:** When compared to LiDAR pointclouds, the quality of structural indices from DAP pointclouds depend on the phenological stages of a deciduous forest.

**Hypothesis 2:** Multitemporal DAP pointclouds are superior than monotemporal pointclouds and are suitable to complement LiDAR derived pointclouds for forest structural analysis.



# Methods

## Study Area


As the study area serves a 200 x 200 m part of a mixed deciduous forest near Marburg (Germany). The area consists of oaks (\textit{Quercus spec.}) and beeches (\textit{Fagus sylvatica}) and represent a typical stand in a managed deciduous forest. Terrain elevation ranges from 250 m to 275 m a.s.l. Stem positions of 500 trees were acquired by using a differential GPS (Zenith 35 Pro, GeoMax Widnau Switzerland) with a positioning accuracy of 0.05 m.\\


## Datasets

The LiDAR data was acquired with a Riegl LMS-Q780 sensor in early spring 2018 under leaf off conditions (Tab. \@ref(tab:tabDatasetOverview)) and provided by the Hessian Agency for Nature Conservation, Environment and Geology - HLNUG. The original pointcloud had an average point density of XX points per square meter with a georeferencing accuracy of 0.3 m horizontally and 0.15 m vertically (Novatel OEM4 GNSS). The LiDAR pointcloud was already classified into ground points and non-ground points by the data provider.  
The DAP pointclouds were acquired with a 3DR Solo Quadrocopter (3D Robotics, Inc., Berkeley CA, USA) and a GoPro Hero 7 camera (GoPro Inc., San Mateo CA, USA) between August and December of 2020. The flight tasks were planned in a uniform altitude above ground at 110 m resulting in a ground sampling distance of 5.6 cm, a side overlap of 75% and a front overlap of 90%. Using the photogrammetric software Metashape (Agisoft LLC, St. Petersburg, Russia), sparse pointclouds were computed from the individual images of each flight. Each sparseclouds was georeferenced with 10 ground control points surveyed with the Real Time Kinematic (RTK) GNSS (Global Navigation Satellite System) device Geomax Zenith 35 (GeoMax AG, Widnau, Switzerland). A detailed explanation of the applied photogrammetic workflow is describe in [@Ludwig2020]. After the referencing, dense pointclouds were computed for each flight from non-resampled depth maps and moderate filtering. 




```{r tabDatasetoverview}

df = read.csv("tables/dataset_overview.csv", header = FALSE)
dfheader = df[1,]
df = df[-1,]

kable(x = df, col.names = dfheader ,row.names = FALSE)

```


## Pointcloud preprocessing and combination

In order to increase the comparability between the pointclouds, each one was homogenized to a density of 50 points per square meter. The classified LiDAR ground points were used to compute a digital elevation model (DEM) with a spatial resolution of 1 m using a k-nearest neighbor algorithm with inverse distance weighting. The DEM was used to normalize the height of each pointcloud which effectively results in a canopy height model (CHM). To eliminate the effects of ground points in the upcoming index calculation, points below 2 m canopy height were removed.  
DAP pointclouds from five different phenological stages during fall 2020 were combined with the leaf-off DAP pointcloud from 2020-12-11. These five multitemporal pointclouds were preprocessed the same way as the individual pointclouds (Fig. \@ref(fig:figWorkflow)). All pointcloud based methods and computations were done in R using the lidR package [@Roussel2020].


```{r figWorkflow}
knitr::include_graphics(path = "figures/pointcloud_processing.pdf")
```



## Common lidar indices

In the review by @Bakx2019, over 10 different studies used this 

Highest LiDAR return in a raster cell (over 10 different studies cited in @Bakx2019 Supplementary Material 3)


Mean height of the canopy surface model (CSM) in the grid cell (first return of the LiDAR). For Gap correction only points above a certain threshold are used (over 10 different studies cited in @Bakx2019 Supplementary Material 3)

### Canopy height

The most reliable application of pointclouds is the estimation of the canopy height. The simplest method is the maximum absolute height of the points in each raster cell $Z_{max}$. However a more realistic approach which is less prone to extreme values is the average height of all points in the 95 percentile ($Z_{mean95}$, Eq. 1).

$$ Z_{mean95} = \frac{\Sigma(Z_{95})}{N_{95}} \;\;\; [1]$$

### Canopy surface models

To assess the overall vertical structure of the canopy, it is a common practice to regard only the first returns of the LiDAR pointclouds and treat them as the so called canopy surface model (CSM). DAP pointclouds do not have return values, however it is a reasonable assumption that here every point represent the canopy, since only spots visible from above the canopy are possible. Therefore the indices $Z\_mean\_csm$ and $Z\_sd\_csm$ were applied to only the first returns of the LiDAR data but all points of the DAP pointclouds.



### Canopy heterogeneity

The horizontal structure of the canopy can be assessed by computing one of the aforementioned indices in a fine resolution (e.g. 1 m) and afterwards calculate the standard deviation for a coarser resolution (e.g. 10 m). Some studies also use the ratio between the mean and the standard deviation in the coarser grid, the so called coefficient of variation [CV, Eq. 2, @Bakx2019].

$$ CV = \frac{Z_{mean}}{Z_{sd}} \;\;\; [2]$$


The vertical canopy structure is usually assessed by calculating the percentile height in each raster cell.

### Normalizing indices values

For better comparability between the different indices, the actual values got normalized to values between zero and one by subtracting the minimum value and divide by the range of the index (Equation 3).

$$ Ind_{norm} = \frac{Ind - min(Ind)}{max(Ind) - min(Ind)} \;\;\;[3]$$





# Results

## Direct comparison of Lidar and DAP

```{r figVertpointsmono, fig.cap="Comparison of the vertical point distribution of LiDAR and single date DAP"}

p = readRDS(file.path(root_folder, "data/level0/pointcloud_height_comparison_single.RDS"))
p
```


```{r figVertpointsmulti, fig.cap="Comparison of the vertical point distribution of LiDAR and combined DAP in spring and fall"}

p = readRDS(file.path(root_folder, "data/level0/pointcloud_height_comparison_comb.RDS"))
p
```




## Resolution and date dependency of indices

```{r figBakx1plots}
bakx_plots = readRDS(file.path(root_folder, "data/results/scatterplots/lidar_densecloud_bakx1_resolutions_plots.RDS"))
bakx_plots[[1]]
```



## Using multitemporal pointclouds


```{r figMultitemporal}

bakx_plots = readRDS(file.path(root_folder, "data/results/scatterplots/lidar_multi_bakx1_resolutions_plots.RDS"))
bakx_plots[[1]]
```


## Quantile height at different resolutions


```{r figVoxelplots}

voxel_plots = readRDS(file.path(root_folder, "data/results/scatterplots/lidar_densecloud_zvoxel_resolutions_plots.RDS"))


voxel_plots[[1]]


```



## Horizontal heterogenity for different dates


```{r figHorizontalsd}
het1 = readRDS(file.path(root_folder, "data/results/scatterplots/lidar_densecloud_bakx1sd_dates_plots.RDS"))
het1

```


```{r figHorizontalsdMulti}
het2 = readRDS(file.path(root_folder, "data/results/scatterplots/lidar_multi_bakx1sd_dates_plots.RDS"))
het2
```



## Date Summary

all these plots use a 2m resolution for the indice calculation

```{r figSummaryIndices, fig.cap="R2 values of linear models between indices of LiDAR pointclouds and DAP pointclouds."}
cors = readRDS(file.path(root_folder, "data/results/lidar_densecloud_correlations/lidar_denseclouds_lm.RDS")) %>% 
  filter(datasource != "lidar") %>% 
  filter(metric_group == "bakx1") %>% 
  filter(metric != "z_shannon") %>% 
  filter(resolution == 2)


ggplot(cors, aes(x = paste0(date, "_",datasource), y = metric, fill = Rsq))+
  geom_raster(alpha = 0.8)+
  scale_fill_gradientn(colors = viridis(50))+
  geom_text(mapping = aes(label = Rsq), col = "black")+
  scale_x_discrete(name = NULL, expand = c(0,0))+
  scale_y_discrete(name = NULL, expand = c(0,0))+
  theme(panel.background = element_blank())+
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

```


```{r figSummaryHeterogenity, fig.cap = "R2 values of linear models between the 10 m standard deviation of indices of LiDAR pointclouds and DAP pointclouds."}

cors = readRDS(file.path(root_folder, "data/results/lidar_densecloud_correlations/lidar_denseclouds_lm.RDS")) %>% 
  filter(datasource != "lidar") %>% 
  filter(metric_group == "bakx1_sd") %>% 
  filter(resolution == 1)


ggplot(cors, aes(x = paste0(date, "_",datasource), y = metric, fill = Rsq))+
  geom_raster(alpha = 0.8)+
  scale_fill_gradientn(colors = viridis(50))+
  geom_text(mapping = aes(label = Rsq), col = "black")+
  ggtitle(cors$metric_group)+
  theme_bw()+
  theme(axis.text.x = element_text(angle = 45, vjust = 0.5))

```


```{r figSummaryVoxelheight}

cors = readRDS(file.path(root_folder, "data/results/lidar_densecloud_correlations/lidar_denseclouds_lm.RDS")) %>% 
  filter(datasource != "lidar") %>% 
  filter(metric_group == "zVoxel") %>% 
  filter(resolution == 2)


ggplot(cors, aes(x = paste0(date, "_",datasource), y = metric, fill = Rsq))+
  geom_raster(alpha = 0.8)+
  scale_fill_gradientn(colors = viridis(50))+
  geom_text(mapping = aes(label = Rsq), col = "black")+
  scale_x_discrete(name = NULL, expand = c(0,0))+
  scale_y_discrete(name = NULL, expand = c(0,0))+
  theme(panel.background = element_blank())+
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

```




# Discussion

Outlook: posibility of individual tree segmentation and then relate to stand variable (Sackov 2019)
or even tree health (Belmonte 2018)


Bad correlations in lower voxel between LiDAR and UAS pointcloud might be because leaf off UAS is able to capture more branches and stems, therefore more points in lower part of the pointcloud (see Fig Distributions). UAS therefore might be better than LiDAR to capture understory vegetation (or at least the potential for understory vegetation) than leaf off LiDAR data
The influence of understory to forest classifications is one common challenge in many studies and identified as a crucial week point




# Text fragments, Backlog


The main challange for further usage of Lidar data in a forest environment is the detection of individual trees. This enables the estimation of tree related parameters such as diameter at breast height, timber volume or crown related metrics [@VanLeeuwen2010]. Forest structure then can be described as the sum of the structure of individual trees [e.g. their height and biomass @Ferraz2016] and the species composition (REF). This could give new insights into ecosystem functioning, since many processes and species distributions depend on functions provided by trees or their related microhabitats (REF). Further, monitoring of individual tree health and drought could be applied in forestry.



### Canopy cover

Usually canopy cover is derived from LiDAR as follows (over 10 different studies cited in @Bakx2019 Supplementary Material 3)

$$ \frac{N_{p > x}}{N_{t}} * 100 $$

with percentage of returns (Np > x) above x meter above ground level at the raster resolution. Nt is the total number of returns. @Bakx2019 also mentiones Farrell et al. 2013 in which a tow part procedure is described: First cover is estimated from aerial photographs, then it is corrected by excluding areas with low canopy height derived from LiDAR. UAS based pointclouds might very suitable for this approach, since the pointcloud and the aerial image are received in the same workflow.

# References

