---
title: "UAS Pointclouds vs. Lidar Pointclouds for structual analysis of forests"
output: html_document
bibliography: /home/marvin/literature/zotero/references.bib
editor_options: 
  chunk_output_type: console
---

```{r setup, include = FALSE}
source("../src/main.R")


knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE, root.dir = root_folder)
knitr::opts_knit$set(root.dir = root_folder)

```

# Introduction


Storyline:

1. Einsatzgebiete von Lidar in Forst und Naturschutz
2. Monitoring dieser Parameter wird gemacht
3. Datenlage bei Lidar dürftig
4. Könnte durch UAV ergänzt werden
5. Dafür muss Vergleichbarkeit getestet werden

The use of Light detection and ranging (LiDAR) pointclouds are well established in forestry, agriculture and forest research. Spatially extensive estimations of vegetation related structural parameters are mostly realised with the calculation of LiDAR indices in a regular grid. Common applications on a forest stand scale are the retrieval of canopy cover and heights [@Lee2018; @Alexander2014], stand density [@Lee2018a] and the estimation of leaf area [@Kamoske2019]. The structural information and its heterogeneity in a landscape serve as indicators for biodiversity [@Hilmers2018] or species occurrence [@Carrasco2019; @Melin2016; @Froidevaux2016]. Most of these Lidar indices are strongly correlated [@Shi2018].

Seasonality of Lidar: max and mean height independent of seasonality, sd and skew of height more dependent on phenology

Comparison of Lidar and UAS based pointclouds for individual tree height (Ganz 2019) revealed very good compariability. Quality of UAS based studies is highly depended on the accuracy of data acuisition and ulitmately proper georeferencing. Dealed with that in Ludwig 2020! 

-> high density pointcloud leads to better results -> lower flight altitudes


When comparing ALS and UAS, using a ALS derived DTM is common in order to normalize the Pointclouds (e.g. Ullag 2019)

Comparisons revealed good potential of UAS pointclouds as a substitude for lidar when estimating common forest attributes (e.g. Ullah 2019, Cao 2019) and to a lesser extent biomass estimations in the tropics (Ota 2015)



Lidar change detection in trees (Duncanson 2018)

EBV framework with 3D information: height, cover and structural complexity
Heterogenous data sources: requires the comparability of Lidar and photogrammetrically recieved pointclouds (Valbuena 2020)






Despite their relevance in forest applications, Lidar data has some major drawbacks, mainly in their cost and accessibility. Lidar sensors and data acquisition are expensive and often distributed commercially. Data provided by governmental institutions are for the most part still irregularly available and not publicly distributed. Further, the temporal resolution of the data is low (by law every 3 years in Germany) making them not suitable for monitoring or applications which require different seasonal conditions. With the recent development of unmanned aerial systems (UAS) and photogrammetric techniques like structure from motion (SfM), an alternative to Lidar pointclouds are available. Quick data access in moderately large areas makes UAS data promising for the monitoring of agricultural or natural systems [@Manfreda2018]. Depending on flight conditions, these pointclouds could be acquired on a near daily basis. Especially in forest environments, research can benefit from vegetation structural information retrieved from UAS data.

Multitemporal UAS can benefit monitoring, e.g. tree growth rates (Guerra-Hernández 2017) or crops (Moeckel2018) 

Multitemporal UAS orthoimages can enhance classification of vegetation types slightly (van Irsel 2018), makes use of plant phenology, most imprtant were july and september because there, green vegetation were at the maximum

Tree height works good in UAS (Fawcett 2019)

Monitoring of Canopy height of crops with multitemporal UAS based CHMs, DEM was build manually with known ground point interpolation (Grüner 2019)

also comparing well to TLS based pointclouds when evaluating plant height in agriculture (Malambo 2018)

Understory trees are a big problem and are not detected in individual tree segmentations (< 35% Goldberg 2018) hence we dont do it here 

However, if trees are detected, the height measurement is well established and consistent across multiple flight dates (e.g. Krause 2019) 

DEM clearly is the week point of photogrammetry (Ota 2015)

Biomass of single trees (in a park) much better under leaf off conditions (Ye 2019)



UAS pointclouds do not have return values which many Lidar indices depend on. Every point is a first return so we cannot get below a developed canopy. These return values however are crucial for LiDAR point classification (e.g. differentiate between ground and non ground point).

The quality and viability of UAS pointclouds have to be assessed in terms of comparability to Lidar pointclouds (since Lidar structural analysis is the standard in many studies)

## Epic 1: Similarities between Lidar and UAS pointclouds


Since photogrammetically received pointclouds only capture the surface and do not penetrate the forest canopy like Lidar pointclouds, different phenological stages should capture different vertical layers of the forest canopy. Therefore, the photogrammetrically received pointcloud should represent and correlate with different parts of the Lidar pointcloud. E.g. a flight without leafs in winter or early spring should correlate well with the last returns of a lidar pointcloud (or a leaf-off lidar campaign) and therefore should be suitable for creating elevation models or the detection of tree stems and branches.

Further, a UAS flight at times with a fully developed canopy leads to pointclouds where it is very unlikely to capture ground points. These pointclouds should be comparable to first returns of a lidar pointcloud. E.g. it was previously shown, that UAS pointclouds are very promising for the estimation of tree heights and canopy cover.

**Hypothesis 1:** Photogrammetrically received pointclouds from different phenological stages in a deciduous forest correlate with different parts of a LiDAR derived pointcloud.

This relationship will be shown by comparing the vertical distributions of both pointclouds in a regular grid. Further, the Lidar data will be filtered to different return counts in order to check, which part of the lidar data is represented.

## Epic 2: Multitemporal UAS pointclouds compared to Lidar pointclouds


If the positional accuracy of the individual photogrammetric pointclouds is high enough (previously shown in @Ludwig2020, it is a resonable assumption to combine pointclouds from different phenological stages in order to get a full 3D model of the forest. The positional accuracy can be validated with tree positions and stem axis surveyed with a totalstation **(How?)**.

**Hypothesis 2:** Mutlitemporal photogrammetrically received pointclouds can substitude Lidar derived pointclouds for forest structural analysis.

This relation will be shown by comparing commonly used structural indices like the `penetration rate` or the estimation of `biomass` from both pointcloud types. Further, the structural data will be validated by field work around at 15 plots where the vertical structure of the forest was assessed.

# Methods

## Study Area


The study area is a 200 x 150 m part of a mixed deciduous forest near Marburg (Germany). The area consists of a mix of oaks (\\textit{Quercus spec.}) and beeches (\\textit{Fagus sylvatica}) and represent a typical environment in a managed forest. The elevation ranges from XXXm to XXXm a.s.l. Stem positions of 500 trees were acquired by using a differential GPS (Zenith 35 Pro, GeoMax Widnau Switzerland) with a positioning accuracy of 0.05 m.\\


## Common lidar indices

### Canopy cover

Usually canopy cover is derived from LiDAR as follows (over 10 different studies cited in @Bakx2019 Supplementary Material 3)

$$ \frac{N_{p > x}}{N_{t}} * 100 $$

with percentage of returns (Np > x) above x meter above ground level at the raster resolution. Nt is the total number of returns. @Bakx2019 also mentiones Farrell et al. 2013 in which a tow part procedure is described: First cover is estimated from aerial photographs, then it is corrected by excluding areas with low canopy height derived from LiDAR. UAS based pointclouds might very suitable for this approach, since the pointcloud and the aerial image are received in the same workflow.

### Canopy height
#### Maximum canopy height (z_max)

Highest LiDAR return in a raster cell (over 10 different studies cited in @Bakx2019 Supplementary Material 3)

$$ Z_{max} $$

#### Mean canopy height 95% (z_mean95)

Mean height of the returns in the 95 percentile (Z95). N95 is the number of returns in the 95 percentile

$$ Z_{mean95} = \frac{\Sigma(Z_{95})}{N_{95}} $$

#### Mean canopy height (z_mean_csm)

Mean height of the canopy surface model (CSM) in the grid cell (first return of the LiDAR). For Gap correction only points above a certain threshold are used (over 10 different studies cited in @Bakx2019 Supplementary Material 3)

### Horizontal canopy variability (index_name_sd)

Usually the standard deviation of the canopy cover or canopy height in larger raster cell (e.g. 10 m - reasonable to get to the sentinel scale!)

### Vertical canopy variability

#### Coefficient of variation of canopy height (CV)

Ratio between mean canopy height (Zmean) and standard deviation (Zsd) of canopy height (5 different studies cited in @Bakx2019)

$$ CV = \frac{Z_{mean}}{Z_{sd}} $$

#### Standard deviation of canopy height (z_sd_csm)

Standard deviation of first returns in a raster cell (over 10 different studies cited in @Bakx2019 Supplementary Material 3)



# Results

## Correlation of common indices in a 1x1 m grid

### Lidar vs. Densecloud 2020-04-28

```{r echo=FALSE, warning=FALSE}
x = stack("data/imports/pointcloud_indices/2018_01_01_lidar/2018_01_01_lidar_01m.grd")
y = stack("data/imports/pointcloud_indices/2020_04_18_densecloud/2020_04_18_densecloud_01m.grd")
pci_plot(x, y)
```

### Lidar vs. Densecloud 2020-04-22

```{r, warning=FALSE, echo = FALSE}
y = stack("data/imports/pointcloud_indices/2020_04_22_densecloud/2020_04_22_densecloud_01m.grd")

pci_plot(x, y)

```


### Lidar vs. Densecloud 2020-09-15

```{r, warning=FALSE, echo = FALSE}
y = stack("data/imports/pointcloud_indices/2020_09_15_densecloud/2020_09_15_densecloud_01m.grd")
pci_plot(x,y)
```


### Lidar vs. Densecloud 2020-11-12

```{r, warning=FALSE, echo = FALSE}
y = stack("data/imports/pointcloud_indices/2020_11_12_densecloud/2020_11_12_densecloud_01m.grd")
pci_plot(x,y)
```

### Lidar vs. Densecloud 2020-12-10

```{r}
y = stack("data/imports/pointcloud_indices/2020_12_10_densecloud/2020_12_10_densecloud_01m.grd")
pci_plot(x,y)

```






### Summary 01m

```{r, eval = FALSE, echo = FALSE}
cors = readRDS("../data/run/correlations_01m.RDS")

ggplot(cors, aes(x = response, y = metric, fill = Rsq))+
  geom_raster(alpha = 0.8)+
  scale_fill_gradientn(colors = viridis(50))+
  geom_text(mapping = aes(label = Rsq), col = "black")+
  theme_bw()+
  theme(axis.text.x = element_text(angle = 45, vjust = 0.5))

```




## Horizontal Heterogenity 10x10m


### Lidar vs. Densecloud 2020-04-18

```{r}
x = stack("data/imports/pointcloud_indices/2018_01_01_lidar/2018_01_01_lidar_heterogenity_10m.grd")
y = stack("data/imports/pointcloud_indices/2020_04_18_densecloud/2020_04_18_densecloud_heterogenity_10m.grd")
pci_plot(x,y)

```


### Lidar vs. Densecloud 2020-09-15

```{r}
y = stack("data/imports/pointcloud_indices/2020_09_15_densecloud/2020_09_15_densecloud_heterogenity_10m.grd")
pci_plot(x,y)

```

### Lidar vs. Densecloud 2020-12-10

```{r}
y = stack("data/imports/pointcloud_indices/2020_12_10_densecloud/2020_12_10_densecloud_heterogenity_10m.grd")
pci_plot(x,y)



```





### Summary 10m

```{r, eval = FALSE,echo = FALSE}
cors = readRDS("../data/run/correlations_10m.RDS")

ggplot(cors, aes(x = response, y = metric, fill = Rsq))+
  geom_raster(alpha = 0.8)+
  scale_fill_gradientn(colors = viridis(50))+
  geom_text(mapping = aes(label = Rsq), col = "black")+
  theme_bw()+
  theme(axis.text.x = element_text(angle = 45, vjust = 0.5))

```

# Discussion

Outlook: posibility of individual tree segmentation and then relate to stand variable (Sackov 2019)
or even tree health (Belmonte 2018)




# Text fragments


The main challange for further usage of Lidar data in a forest environment is the detection of individual trees. This enables the estimation of tree related parameters such as diameter at breast height, timber volume or crown related metrics [@Leeuwen2010]. Forest structure then can be described as the sum of the structure of individual trees [e.g. their height and biomass @Ferraz2016] and the species composition (REF). This could give new insights into ecosystem functioning, since many processes and species distributions depend on functions provided by trees or their related microhabitats (REF). Further, monitoring of individual tree health and drought could be applied in forestry.


# References

